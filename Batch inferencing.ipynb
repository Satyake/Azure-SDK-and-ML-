{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, Workspace, Model, Environment,Datastore, Dataset\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws=Workspace.get(name='azuremlsdk-ws01', subscription_id='1db33695-8135-4616-9bb4-9574b401d454', resource_group='azuremlsdk-rg01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore=Datastore.register_azure_blob_container(workspace=ws,datastore_name='diabetesdatastore',container_name='diabetes',account_key='vUU8jFjAcXAmXUID475MCQ+C0Fn15wAxIXPPf76k+R30PVCoEBElx4fUCMevI0AXiiQerijgnF/H+ASt1Nm3bA==',\n",
    "account_name='storagerrg01',create_if_not_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=Dataset.Tabular.from_delimited_files(path=[(datastore,'diabetes.csv')])\n",
    "dataset=dataset.register(workspace=ws,name='diabetes')\n",
    "dataset_df=dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.head()\n",
    "#dataset_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\satya\\anaconda3\\envs\\tf-gpu-cuda8\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "experiment=Experiment(ws, 'modeltrainingdiabetes')\n",
    "run=experiment.start_logging(snapshot_directory=None)\n",
    "x=dataset_df.iloc[:,:-1].values\n",
    "y=dataset_df.iloc[:,-1].values\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "LR=LogisticRegression()\n",
    "fitted_model=LR.fit(x_train,y_train)\n",
    "run.log('Accuracy',fitted_model.score(x_test,y_test))\n",
    "path='./outputs/model.pkl'\n",
    "joblib.dump(value=fitted_model,filename=path)\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#register model\n",
    "model=run.register_model(model_name='diabetesmodel',model_path='outputs/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating pipeline\n",
    "import os\n",
    "experiment_folder='batch_pipeline'\n",
    "os.makedirs(experiment_folder,exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220616.v1\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"batch_env\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.13\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults~=1.43.0\",\n",
       "                        \"azureml-core~=1.43.0\"\n",
       "                    ]\n",
       "                },\n",
       "                \"scikit-learn\",\n",
       "                \"pandas\",\n",
       "                \"numpy\"\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"2\"\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "env=Environment('batch_env')\n",
    "dep=CondaDependencies.create(conda_packages=['scikit-learn','pandas','numpy'],pip_packages=['azureml-defaults','azureml-core'])\n",
    "env.python.conda_dependencies=dep\n",
    "env.register(workspace=ws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>106</th>\n",
       "      <th>76</th>\n",
       "      <th>0</th>\n",
       "      <th>0_1</th>\n",
       "      <th>37.5</th>\n",
       "      <th>0.197</th>\n",
       "      <th>26</th>\n",
       "      <th>0_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>190</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.278</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.766</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>170</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.142</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    1  106  76   0  0_1  37.5  0.197  26  0_2\n",
       "0   6  190  92   0    0  35.5  0.278  66    1\n",
       "1   2   88  58  26   16  28.4  0.766  22    0\n",
       "2   9  170  74  31    0  44.0  0.403  43    1\n",
       "3   9   89  62   0    0  22.5  0.142  33    0\n",
       "4  10  101  76  48  180  32.9  0.171  63    0\n",
       "5   2  122  70  27    0  36.8  0.340  27    0\n",
       "6   5  121  72  23  112  26.2  0.245  30    0\n",
       "7   1  126  60   0    0  30.1  0.349  47    1\n",
       "8   1   93  70  31    0  30.4  0.315  23    0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv=[(datastore,'batch_dia.csv')]\n",
    "dataset_batch=Dataset.Tabular.from_delimited_files(path=csv)\n",
    "dataset_batch=dataset_batch.register(workspace=ws,name='batch_dataset_test',create_new_version=True)\n",
    "dataset_batch.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress.\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "#compute\n",
    "cluster_name='cluster1'\n",
    "compute_config=AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',max_nodes=4)\n",
    "compute_target=ComputeTarget.create(ws,cluster_name,compute_config)\n",
    "compute_target.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_diabetes.py\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "#import Model\n",
    "from azureml.core.model import Model\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path=Model.get_model_path(model_name='diabetesmodel')\n",
    "    model=joblib.load(model_path)\n",
    "\n",
    "def run(mini_batch):\n",
    "    results=[]\n",
    "    for f in mini_batch:\n",
    "        #read comma delimited data into an array\n",
    "        data=np.genfromtxt(f,delimiter=',')\n",
    "        prediction=model.predict(data.reshape(1,-1))\n",
    "        results.append(\"{}: {}\".format(os.path.basename(f),prediction[0]))\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created!\n",
      "Saving files...\n",
      "files saved!\n",
      "Uploading files to datastore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"Datastore.upload\" is deprecated after version 1.0.69. Please use \"Dataset.File.upload_directory\" to upload your files             from a local directory and create FileDataset in single method call. See Dataset API change notice at https://aka.ms/dataset-deprecation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data\\1.csv\n",
      "Uploaded batch-data\\1.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data\\10.csv\n",
      "Uploaded batch-data\\10.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data\\100.csv\n",
      "Uploaded batch-data\\100.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data\\11.csv\n",
      "Uploaded batch-data\\11.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data\\12.csv\n",
      "Uploaded batch-data\\12.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data\\13.csv\n",
      "Uploaded batch-data\\13.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data\\14.csv\n",
      "Uploaded batch-data\\14.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data\\15.csv\n",
      "Uploaded batch-data\\15.csv, 8 files out of an estimated total of 100\n",
      "Uploading batch-data\\16.csv\n",
      "Uploaded batch-data\\16.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data\\17.csv\n",
      "Uploaded batch-data\\17.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data\\18.csv\n",
      "Uploaded batch-data\\18.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data\\19.csv\n",
      "Uploaded batch-data\\19.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data\\2.csv\n",
      "Uploaded batch-data\\2.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data\\20.csv\n",
      "Uploaded batch-data\\20.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data\\22.csv\n",
      "Uploaded batch-data\\22.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data\\23.csv\n",
      "Uploaded batch-data\\23.csv, 16 files out of an estimated total of 100\n",
      "Uploading batch-data\\24.csv\n",
      "Uploaded batch-data\\24.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data\\25.csv\n",
      "Uploaded batch-data\\25.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data\\26.csv\n",
      "Uploaded batch-data\\26.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data\\27.csv\n",
      "Uploaded batch-data\\27.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data\\28.csv\n",
      "Uploaded batch-data\\28.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data\\29.csv\n",
      "Uploaded batch-data\\29.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data\\3.csv\n",
      "Uploaded batch-data\\3.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data\\30.csv\n",
      "Uploaded batch-data\\30.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data\\31.csv\n",
      "Uploaded batch-data\\31.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data\\32.csv\n",
      "Uploaded batch-data\\32.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data\\33.csv\n",
      "Uploaded batch-data\\33.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data\\34.csv\n",
      "Uploaded batch-data\\34.csv, 28 files out of an estimated total of 100\n",
      "Uploading batch-data\\35.csv\n",
      "Uploaded batch-data\\35.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data\\36.csv\n",
      "Uploaded batch-data\\36.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data\\37.csv\n",
      "Uploaded batch-data\\37.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data\\38.csv\n",
      "Uploaded batch-data\\38.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data\\39.csv\n",
      "Uploaded batch-data\\39.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data\\4.csv\n",
      "Uploaded batch-data\\4.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data\\40.csv\n",
      "Uploaded batch-data\\40.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data\\41.csv\n",
      "Uploaded batch-data\\41.csv, 36 files out of an estimated total of 100\n",
      "Uploading batch-data\\42.csv\n",
      "Uploaded batch-data\\42.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data\\43.csv\n",
      "Uploaded batch-data\\43.csv, 38 files out of an estimated total of 100\n",
      "Uploading batch-data\\44.csv\n",
      "Uploaded batch-data\\44.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data\\45.csv\n",
      "Uploaded batch-data\\45.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data\\46.csv\n",
      "Uploaded batch-data\\46.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data\\47.csv\n",
      "Uploaded batch-data\\47.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data\\48.csv\n",
      "Uploaded batch-data\\48.csv, 43 files out of an estimated total of 100\n",
      "Uploading batch-data\\49.csv\n",
      "Uploaded batch-data\\49.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data\\5.csv\n",
      "Uploaded batch-data\\5.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data\\50.csv\n",
      "Uploaded batch-data\\50.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data\\51.csv\n",
      "Uploaded batch-data\\51.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data\\52.csv\n",
      "Uploaded batch-data\\52.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data\\53.csv\n",
      "Uploaded batch-data\\53.csv, 49 files out of an estimated total of 100\n",
      "Uploading batch-data\\54.csv\n",
      "Uploaded batch-data\\54.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data\\55.csv\n",
      "Uploaded batch-data\\55.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data\\56.csv\n",
      "Uploaded batch-data\\56.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data\\57.csv\n",
      "Uploaded batch-data\\57.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data\\58.csv\n",
      "Uploaded batch-data\\58.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data\\59.csv\n",
      "Uploaded batch-data\\59.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data\\6.csv\n",
      "Uploaded batch-data\\6.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data\\60.csv\n",
      "Uploaded batch-data\\60.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data\\61.csv\n",
      "Uploaded batch-data\\61.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data\\62.csv\n",
      "Uploaded batch-data\\62.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data\\63.csv\n",
      "Uploaded batch-data\\63.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data\\64.csv\n",
      "Uploaded batch-data\\64.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data\\65.csv\n",
      "Uploaded batch-data\\65.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data\\66.csv\n",
      "Uploaded batch-data\\66.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data\\67.csv\n",
      "Uploaded batch-data\\67.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data\\68.csv\n",
      "Uploaded batch-data\\68.csv, 65 files out of an estimated total of 100\n",
      "Uploading batch-data\\69.csv\n",
      "Uploaded batch-data\\69.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data\\7.csv\n",
      "Uploaded batch-data\\7.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data\\70.csv\n",
      "Uploaded batch-data\\70.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data\\71.csv\n",
      "Uploaded batch-data\\71.csv, 69 files out of an estimated total of 100\n",
      "Uploading batch-data\\72.csv\n",
      "Uploaded batch-data\\72.csv, 70 files out of an estimated total of 100\n",
      "Uploading batch-data\\73.csv\n",
      "Uploaded batch-data\\73.csv, 71 files out of an estimated total of 100\n",
      "Uploading batch-data\\74.csv\n",
      "Uploaded batch-data\\74.csv, 72 files out of an estimated total of 100\n",
      "Uploading batch-data\\75.csv\n",
      "Uploaded batch-data\\75.csv, 73 files out of an estimated total of 100\n",
      "Uploading batch-data\\76.csv\n",
      "Uploaded batch-data\\76.csv, 74 files out of an estimated total of 100\n",
      "Uploading batch-data\\77.csv\n",
      "Uploaded batch-data\\77.csv, 75 files out of an estimated total of 100\n",
      "Uploading batch-data\\78.csv\n",
      "Uploaded batch-data\\78.csv, 76 files out of an estimated total of 100\n",
      "Uploading batch-data\\79.csv\n",
      "Uploaded batch-data\\79.csv, 77 files out of an estimated total of 100\n",
      "Uploading batch-data\\8.csv\n",
      "Uploaded batch-data\\8.csv, 78 files out of an estimated total of 100\n",
      "Uploading batch-data\\80.csv\n",
      "Uploaded batch-data\\80.csv, 79 files out of an estimated total of 100\n",
      "Uploading batch-data\\81.csv\n",
      "Uploaded batch-data\\81.csv, 80 files out of an estimated total of 100\n",
      "Uploading batch-data\\82.csv\n",
      "Uploaded batch-data\\82.csv, 81 files out of an estimated total of 100\n",
      "Uploading batch-data\\83.csv\n",
      "Uploaded batch-data\\83.csv, 82 files out of an estimated total of 100\n",
      "Uploading batch-data\\84.csv\n",
      "Uploaded batch-data\\84.csv, 83 files out of an estimated total of 100\n",
      "Uploading batch-data\\85.csv\n",
      "Uploaded batch-data\\85.csv, 84 files out of an estimated total of 100\n",
      "Uploading batch-data\\86.csv\n",
      "Uploaded batch-data\\86.csv, 85 files out of an estimated total of 100\n",
      "Uploading batch-data\\87.csv\n",
      "Uploaded batch-data\\87.csv, 86 files out of an estimated total of 100\n",
      "Uploading batch-data\\88.csv\n",
      "Uploaded batch-data\\88.csv, 87 files out of an estimated total of 100\n",
      "Uploading batch-data\\89.csv\n",
      "Uploaded batch-data\\89.csv, 88 files out of an estimated total of 100\n",
      "Uploading batch-data\\9.csv\n",
      "Uploaded batch-data\\9.csv, 89 files out of an estimated total of 100\n",
      "Uploading batch-data\\90.csv\n",
      "Uploaded batch-data\\90.csv, 90 files out of an estimated total of 100\n",
      "Uploading batch-data\\91.csv\n",
      "Uploaded batch-data\\91.csv, 91 files out of an estimated total of 100\n",
      "Uploading batch-data\\92.csv\n",
      "Uploaded batch-data\\92.csv, 92 files out of an estimated total of 100\n",
      "Uploading batch-data\\93.csv\n",
      "Uploaded batch-data\\93.csv, 93 files out of an estimated total of 100\n",
      "Uploading batch-data\\94.csv\n",
      "Uploaded batch-data\\94.csv, 94 files out of an estimated total of 100\n",
      "Uploading batch-data\\95.csv\n",
      "Uploaded batch-data\\95.csv, 95 files out of an estimated total of 100\n",
      "Uploading batch-data\\96.csv\n",
      "Uploaded batch-data\\96.csv, 96 files out of an estimated total of 100\n",
      "Uploading batch-data\\97.csv\n",
      "Uploaded batch-data\\97.csv, 97 files out of an estimated total of 100\n",
      "Uploading batch-data\\98.csv\n",
      "Uploaded batch-data\\98.csv, 98 files out of an estimated total of 100\n",
      "Uploading batch-data\\99.csv\n",
      "Uploaded batch-data\\99.csv, 99 files out of an estimated total of 100\n",
      "Uploading batch-data\\21.csv\n",
      "Uploaded batch-data\\21.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Load the diabetes data\n",
    "diabetes = pd.read_csv('C:/Users/satya/Downloads/archive (9)/diabetes.csv')\n",
    "# Get a 100-item sample of the feature columns (not the diabetic label)\n",
    "sample = diabetes[['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']].sample(n=100).values\n",
    "\n",
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")\n",
    "\n",
    "# Save each sample as a separate file\n",
    "print(\"Saving files...\")\n",
    "for i in range(100):\n",
    "    fname = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
    "print(\"files saved!\")\n",
    "\n",
    "# Upload the files to the default datastore\n",
    "print(\"Uploading files to datastore...\")\n",
    "default_ds = Datastore.get(ws,'diabetesdatastore')\n",
    "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='batch-data',\n",
    "                                             description='batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batching pipeline\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.data import OutputFileDatasetConfig\n",
    "\n",
    "output_dir=OutputFileDatasetConfig(name='inferences')\n",
    "ds=Datastore.get(ws,'diabetesdatastore')\n",
    "#output_dir=PipelineData(name='inferences',datastore=ds,output_path_on_compute='diabetes/results')\n",
    "\n",
    "parrallel_run_config=ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script='batch_diabetes.py',\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action='append_row',\n",
    "    environment=env,\n",
    "    compute_target=compute_target,\n",
    "    node_count=1\n",
    ")\n",
    "\n",
    "parrallel_run_step=ParallelRunStep(\n",
    "    name='batch_inference',\n",
    "    parallel_run_config=parrallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('raw_data')],\n",
    "    output= output_dir,\n",
    "    allow_reuse=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch_inference [935f2595][9358729a-313e-454f-987b-129e6f010275], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 69b19816-7b0c-423f-acb5-a35145dcf779\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/69b19816-7b0c-423f-acb5-a35145dcf779?wsid=/subscriptions/1db33695-8135-4616-9bb4-9574b401d454/resourcegroups/azuremlsdk-rg01/workspaces/azuremlsdk-ws01&tid=6ad91895-de06-485e-bc51-fce126cc8530\n",
      "PipelineRunId: 69b19816-7b0c-423f-acb5-a35145dcf779\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/69b19816-7b0c-423f-acb5-a35145dcf779?wsid=/subscriptions/1db33695-8135-4616-9bb4-9574b401d454/resourcegroups/azuremlsdk-rg01/workspaces/azuremlsdk-ws01&tid=6ad91895-de06-485e-bc51-fce126cc8530\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: a618362e-3763-4709-9406-66bdcf7bd0b3\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/a618362e-3763-4709-9406-66bdcf7bd0b3?wsid=/subscriptions/1db33695-8135-4616-9bb4-9574b401d454/resourcegroups/azuremlsdk-rg01/workspaces/azuremlsdk-ws01&tid=6ad91895-de06-485e-bc51-fce126cc8530\n",
      "StepRun( batch_inference ) Status: NotStarted\n",
      "StepRun( batch_inference ) Status: Running\n",
      "\n",
      "StepRun(batch_inference) Execution Summary\n",
      "===========================================\n",
      "StepRun( batch_inference ) Status: Finished\n",
      "{'runId': 'a618362e-3763-4709-9406-66bdcf7bd0b3', 'target': 'cluster1', 'status': 'Completed', 'startTimeUtc': '2023-01-06T22:49:53.565291Z', 'endTimeUtc': '2023-01-06T22:51:56.558029Z', 'services': {}, 'properties': {'ContentSnapshotId': '039e7d9b-2b6c-474e-b905-8fa0e0c79b8a', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '9358729a-313e-454f-987b-129e6f010275', 'azureml.moduleName': 'batch_inference', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '935f2595', 'azureml.pipelinerunid': '69b19816-7b0c-423f-acb5-a35145dcf779', 'azureml.pipeline': '69b19816-7b0c-423f-acb5-a35145dcf779', 'azureml.pipelineComponent': 'masterescloud', 'azureml.parallelrunstep': 'true', '_azureml.ComputeTargetType': 'amlctrain', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '5beb41e1-64ac-43a6-b477-cce2c9c5e7f9'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Mount'}}], 'outputDatasets': [{'identifier': {'savedId': '89bc438f-d36e-47f4-9c55-653cb8a11acd'}, 'outputType': 'RunOutput', 'outputDetails': {'outputName': 'inferences'}, 'dataset': {\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'dataset/a618362e-3763-4709-9406-66bdcf7bd0b3/inferences/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"89bc438f-d36e-47f4-9c55-653cb8a11acd\",\n",
      "    \"name\": null,\n",
      "    \"version\": null,\n",
      "    \"workspace\": \"Workspace.create(name='azuremlsdk-ws01', subscription_id='1db33695-8135-4616-9bb4-9574b401d454', resource_group='azuremlsdk-rg01')\"\n",
      "  }\n",
      "}}], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.43.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', 'DatasetOutputConfig:inferences', '--input_fds_0', 'raw_data'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'cluster1', 'dataReferences': {}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '5beb41e1-64ac-43a6-b477-cce2c9c5e7f9', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False, 'options': None}}, 'outputData': {'inferences': {'outputLocation': {'dataset': None, 'dataPath': {'datastoreName': 'workspaceblobstore', 'relativePath': None}, 'uri': None, 'type': None}, 'mechanism': 'Mount', 'additionalOptions': {'pathOnCompute': None, 'registrationOptions': {'name': None, 'description': None, 'tags': None, 'properties': {'azureml.pipelineRunId': '69b19816-7b0c-423f-acb5-a35145dcf779', 'azureml.pipelineRun.moduleNodeId': '935f2595', 'azureml.pipelineRun.outputPortName': 'inferences'}, 'datasetRegistrationOptions': {'additionalTransformation': None}}, 'uploadOptions': {'overwrite': False, 'sourceGlobs': {'globPatterns': None}}, 'mountOptions': None}, 'environmentVariableName': None}}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'instanceTypes': [], 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'batch_env', 'version': '2', 'assetId': 'azureml://locations/eastus2/workspaces/564a5ba3-db0b-4e34-ae1f-9eea51aaacb6/environments/batch_env/versions/2', 'autoRebuild': True, 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'name': 'project_environment', 'dependencies': ['python=3.8.13', {'pip': ['azureml-defaults~=1.43.0', 'azureml-core~=1.43.0']}, 'scikit-learn', 'pandas', 'numpy'], 'channels': ['anaconda', 'conda-forge']}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220616.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': 'D2', 'imageVersion': 'pytorch-1.7.0', 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None, 'sshPublicKeys': None, 'enableAzmlInt': True, 'priority': 'Medium', 'slaTier': 'Standard', 'userAlias': None}, 'kubernetesCompute': {'instanceType': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}, 'parameters': []}, 'logFiles': {'logs/azureml/executionlogs.txt': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=MJC%2BJlIBOssns3gvERSUX2NphB%2Bt%2BotqeixKCQjxs8w%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A40%3A00Z&se=2023-01-07T06%3A50%3A00Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=MqLB5cvHDLIlv1LgL1gFjhO0AS5R91epbIyeukI5p60%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A40%3A00Z&se=2023-01-07T06%3A50%3A00Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=CKIF3MHBCzkalcsYwO97A%2BuWUVsWOsVYTlTherQfGyo%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A40%3A00Z&se=2023-01-07T06%3A50%3A00Z&sp=r', 'user_logs/std_log_0.txt': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/user_logs/std_log_0.txt?sv=2019-07-07&sr=b&sig=3UZ1dbEQ7IwnKrbMG%2FvVoUOyF7%2ByfTxgj4Wl61IIIYo%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/cs_capability/0/cs-capability.log': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/cs_capability/0/cs-capability.log?sv=2019-07-07&sr=b&sig=z5gveoc1TpNPHzgErx%2FSfYit4t8%2Fl1Q%2BF49JsGhYmhI%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/data_capability/0/data-capability.log': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/data_capability/0/data-capability.log?sv=2019-07-07&sr=b&sig=etmxulAcaCW7wiXO6iDcSYLK8q8fL7V5w5sZQDUmpfI%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/data_capability/0/rslex.log.2023-01-06-22': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/data_capability/0/rslex.log.2023-01-06-22?sv=2019-07-07&sr=b&sig=0Zh1%2FS2sytZxYSiiraq%2BU2Y76xzXVGARVxhhBSESU9c%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/hosttools_capability/0/hosttools-capability.log': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/hosttools_capability/0/hosttools-capability.log?sv=2019-07-07&sr=b&sig=2vIh9DUlJNw0RdlKmmy50h5GLpM8m4v3irxEMFdhSNM%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/lifecycler/0/execution-wrapper.log': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/lifecycler/0/execution-wrapper.log?sv=2019-07-07&sr=b&sig=G0J1RoW0stpGBDmC5RFC8kXp2m2nvKxwiLnQPbQ2aP4%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/lifecycler/0/lifecycler.log': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/lifecycler/0/lifecycler.log?sv=2019-07-07&sr=b&sig=MEY6hFVv8sd6oxqvCVor3mFns40clGIDS%2Fw6ArRn61s%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/metrics_capability/0/metrics-capability.log': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/metrics_capability/0/metrics-capability.log?sv=2019-07-07&sr=b&sig=VZ2NRILtwSY%2BRgjpb3KNEZLr2ZxCOjJF6OenH%2BGoMLI%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r', 'system_logs/snapshot_capability/0/snapshot-capability.log': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.a618362e-3763-4709-9406-66bdcf7bd0b3/system_logs/snapshot_capability/0/snapshot-capability.log?sv=2019-07-07&sr=b&sig=BEqfdUUcjg4FQHrccQRkg1zLoiOjHs5Nw8rPyhseZ2s%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A41%3A59Z&se=2023-01-07T06%3A51%3A59Z&sp=r'}, 'submittedBy': 'Satyake Bakshi'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '69b19816-7b0c-423f-acb5-a35145dcf779', 'status': 'Completed', 'startTimeUtc': '2023-01-06T22:49:52.245404Z', 'endTimeUtc': '2023-01-06T22:51:58.106058Z', 'services': {}, 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.pipelineComponent': 'pipelinerun', 'azureml.pipelines.stages': '{\"Initialization\":null,\"Execution\":{\"StartTime\":\"2023-01-06T22:49:52.4802412+00:00\",\"EndTime\":\"2023-01-06T22:51:58.0233756+00:00\",\"Status\":\"Finished\"}}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.69b19816-7b0c-423f-acb5-a35145dcf779/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=Rc2VRMYvJq9W7U5hDM8VC9n7G%2F6CW4ouuO5SsUnd9kg%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A42%3A01Z&se=2023-01-07T06%3A52%3A01Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.69b19816-7b0c-423f-acb5-a35145dcf779/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=j%2BnIEl0bnY1Sm5pYHtniYM6coZPHSLcQlPkzumcYmmc%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A42%3A01Z&se=2023-01-07T06%3A52%3A01Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://azuremlsstorage216301655.blob.core.windows.net/azureml/ExperimentRun/dcid.69b19816-7b0c-423f-acb5-a35145dcf779/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=vWLHDTFbRdxCQBm3VYCmszSaG3g32qgs4YyQb9womgM%3D&skoid=d0a5bd9a-86d3-472e-9722-1c8a0d8f296a&sktid=6ad91895-de06-485e-bc51-fce126cc8530&skt=2023-01-06T17%3A11%3A10Z&ske=2023-01-08T01%3A21%3A10Z&sks=b&skv=2019-07-07&st=2023-01-06T22%3A42%3A01Z&se=2023-01-07T06%3A52%3A01Z&sp=r'}, 'submittedBy': 'Satyake Bakshi'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "pipeline=Pipeline(workspace=ws,steps=[parrallel_run_step])\n",
    "pipeline_run=pipeline.submit(experiment_name='batch_pipeline')\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-cuda8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03f4ac3119e2450266d45ef487def59165e9739e84fca1acfa1dc135d1f5e0c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
